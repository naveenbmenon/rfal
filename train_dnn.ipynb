{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "NUM_CLASSES = None   # will auto-detect\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "# =========================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =========================\n",
    "X = np.load(\"X_dnn.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "\n",
    "print(\"Loaded:\", X.shape, y.shape)\n",
    "\n",
    "# Auto-detect classes\n",
    "NUM_CLASSES = len(np.unique(y))\n",
    "print(\"Detected classes:\", NUM_CLASSES)\n",
    "\n",
    "# Shuffle entire dataset\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# SPLIT (70 / 15 / 15)\n",
    "# =========================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:  \", X_val.shape)\n",
    "print(\"Test: \", X_test.shape)\n",
    "\n",
    "# =========================\n",
    "# NORMALIZE (based on train only)\n",
    "# =========================\n",
    "mean = np.mean(X_train)\n",
    "std = np.std(X_train) + 1e-8\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_val   = (X_val   - mean) / std\n",
    "X_test  = (X_test  - mean) / std\n",
    "\n",
    "# =========================\n",
    "# ONE-HOT ENCODE\n",
    "# =========================\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val   = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test  = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# =========================\n",
    "# BUILD DNN MODEL\n",
    "# =========================\n",
    "model = Sequential([\n",
    "    Dense(256, activation=\"tanh\", input_shape=(X.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation=\"tanh\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"tanh\"),\n",
    "    Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# =========================\n",
    "# TRAIN\n",
    "# =========================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# TEST\n",
    "# =========================\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nDNN Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18dfc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# =========================\n",
    "# PREDICTIONS\n",
    "# =========================\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "NUM_CLASSES = y_test.shape[1]\n",
    "class_names = [f\"TX {i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "# =========================\n",
    "# CLASSIFICATION REPORT\n",
    "# =========================\n",
    "print(\"\\n==============================\")\n",
    "print(\" DNN CLASSIFICATION REPORT\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=class_names,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# =========================\n",
    "# CONFUSION MATRIX (RAW)\n",
    "# =========================\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=class_names\n",
    ")\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"DNN Confusion Matrix (Counts)\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# CONFUSION MATRIX (NORMALIZED)\n",
    "# =========================\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "disp_norm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_norm,\n",
    "    display_labels=class_names\n",
    ")\n",
    "disp_norm.plot(cmap=\"Blues\", values_format=\".2f\")\n",
    "plt.title(\"DNN Confusion Matrix (Normalized)\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# PER-CLASS ACCURACY\n",
    "# =========================\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for c, name in enumerate(class_names):\n",
    "    idx = y_true == c\n",
    "    acc = np.mean(y_pred[idx] == c)\n",
    "    print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall Test Accuracy: {np.mean(y_true == y_pred):.4f}\")\n",
    "\n",
    "# =========================\n",
    "# CORRECT vs INCORRECT IQ SCATTER\n",
    "# =========================\n",
    "cls = 0  # change transmitter index here\n",
    "\n",
    "correct_idx = np.where((y_true == cls) & (y_pred == cls))[0][:200]\n",
    "wrong_idx   = np.where((y_true == cls) & (y_pred != cls))[0][:200]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# Correct predictions\n",
    "if len(correct_idx) > 0:\n",
    "    I_correct = X_test[correct_idx][:, 0::2].flatten()\n",
    "    Q_correct = X_test[correct_idx][:, 1::2].flatten()\n",
    "    plt.scatter(I_correct, Q_correct, s=1, alpha=0.3, label=\"Correct\")\n",
    "\n",
    "# Incorrect predictions\n",
    "if len(wrong_idx) > 0:\n",
    "    I_wrong = X_test[wrong_idx][:, 0::2].flatten()\n",
    "    Q_wrong = X_test[wrong_idx][:, 1::2].flatten()\n",
    "    plt.scatter(I_wrong, Q_wrong, s=1, alpha=0.5, label=\"Misclassified\")\n",
    "\n",
    "plt.xlabel(\"In-phase (I)\")\n",
    "plt.ylabel(\"Quadrature (Q)\")\n",
    "plt.title(f\"DNN IQ Scatter â€“ TX {cls}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
